# Distillation Job Runner - Template for layer graduation
# This is a placeholder/template that demonstrates the distillation pipeline
# Actual jobs will be triggered manually with specific layer parameters

apiVersion: v1
kind: ServiceAccount
metadata:
  name: distillation-runner
  namespace: cortex-ai-infra
  labels:
    app.kubernetes.io/part-of: cortex
    cortex.ai/substrate: "true"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: distillation-runner
  labels:
    cortex.ai/substrate: "true"
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log", "services", "configmaps"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "patch"]
- apiGroups: ["apps"]
  resources: ["deployments", "statefulsets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list", "watch", "create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: distillation-runner
  labels:
    cortex.ai/substrate: "true"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: distillation-runner
subjects:
- kind: ServiceAccount
  name: distillation-runner
  namespace: cortex-ai-infra
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: distillation-pipeline
  namespace: cortex-ai-infra
  labels:
    cortex.ai/substrate: "true"
data:
  README.md: |
    # Distillation Pipeline

    ## Purpose
    Transform operational layer behavior into specialized models.

    ## Timeline (Per Layer)
    - Cold Start: 0-2 weeks (0-1K samples) - Just collecting
    - Learning: 2-8 weeks (1K-10K samples) - Monitor quality
    - Eligible: 8+ weeks (10K+ samples) - >85% success, <10% entropy
    - Distillation: Manual trigger for v1, automated later

    ## Process
    1. Collect telemetry from layer (MoE decisions, vector lookups, tool chains)
    2. Filter for high-quality samples (successful task completions)
    3. Generate training dataset from operational traces
    4. Train LoRA adapter (2-4 hours) or full fine-tune (4-6 hours)
    5. Deploy specialized model to replace MoE+RAG stack
    6. Monitor for quality regression
    7. Scale down original burst stack if successful

    ## Manual Trigger Example
    ```bash
    kubectl create job -n cortex-ai-infra distill-knowledge-layer-v1 \
      --from=cronjob/distillation-template \
      -- --layer=cortex-knowledge \
         --min-samples=5000 \
         --quality-threshold=0.85 \
         --method=lora
    ```

    ## Quality Gates
    - Minimum 5,000 quality samples
    - Success rate >85%
    - Routing entropy <10% (consistency)
    - Manual approval for first distillation

    ## Output
    - Specialized model pushed to registry
    - Deployment manifest for cortex-ai-infra or layer namespace
    - Performance comparison report
    - Rollback plan
