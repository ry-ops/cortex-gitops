apiVersion: v1
kind: ConfigMap
metadata:
  name: blog-writer-source
  namespace: cortex-school
data:
  app.py: |
    #!/usr/bin/env python3
    """
    Cortex Blog Writer
    Generates blog posts about Cortex's learning journey
    """
    import os
    import json
    import time
    import logging
    import subprocess
    from datetime import datetime
    from flask import Flask, jsonify
    from redis import Redis
    import anthropic

    # Configure logging
    logging.basicConfig(level=os.getenv('LOG_LEVEL', 'INFO'))
    logger = logging.getLogger(__name__)

    app = Flask(__name__)

    # Configuration
    REDIS_HOST = os.getenv('REDIS_HOST', 'redis-queue.cortex.svc.cluster.local')
    REDIS_PORT = int(os.getenv('REDIS_PORT', '6379'))
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
    BLOG_REPO_PATH = os.getenv('BLOG_REPO_PATH', '/blog')
    RELEVANCE_THRESHOLD = float(os.getenv('RELEVANCE_THRESHOLD', '0.90'))
    GITHUB_USER_EMAIL = os.getenv('GITHUB_USER_EMAIL', 'cortex@cortex-io.com')
    GITHUB_USER_NAME = os.getenv('GITHUB_USER_NAME', 'Cortex')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
    POLL_INTERVAL = int(os.getenv('POLL_INTERVAL', '300'))  # 5 minutes
    CLOUDFLARE_API_TOKEN = os.getenv('CLOUDFLARE_API_TOKEN')
    CLOUDFLARE_ACCOUNT_ID = os.getenv('CLOUDFLARE_ACCOUNT_ID')
    CLOUDFLARE_PROJECT_NAME = os.getenv('CLOUDFLARE_PROJECT_NAME', 'blog')
    CLOUDFLARE_VERIFY_DEPLOYMENT = os.getenv('CLOUDFLARE_VERIFY_DEPLOYMENT', 'true').lower() == 'true'

    # Redis connection
    redis_client = Redis(host=REDIS_HOST, port=REDIS_PORT, decode_responses=True)

    # Anthropic client
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

    # Category mapping for blog posts
    CATEGORY_MAP = {
        'knowledge': 'AI & ML',
        'skill': 'Developer skills',
        'monitoring': 'Engineering',
        'capability': 'Engineering',
        'architecture': 'Engineering',
        'security': 'Security',
        'database': 'Engineering',
        'integration': 'Engineering'
    }

    def get_svg_hero_spec():
        """Return the SVG hero generation spec"""
        return """You are generating an animated SVG hero image for a blog post.

    MANDATORY RULES:
    1. Dimensions: 1200x630 (viewBox="0 0 1200 630")
    2. NO TEXT - absolutely no text, labels, or typography
    3. ANIMATED - must include CSS animations (not SMIL)
    4. Self-contained - all styles embedded in <style> tags
    5. Unique - never reuse designs

    ANIMATION REQUIREMENTS:
    - Use CSS @keyframes animations
    - Duration: 4s-15s (slow, ambient movement)
    - Prefer transform and opacity (GPU-accelerated)
    - Max 15-20 animated elements
    - Smooth easing (ease-in-out)

    Return ONLY the SVG code, no markdown fences, no explanation."""

    def generate_svg_hero(post_title, category):
        """Generate animated SVG hero image using Claude"""
        try:
            prompt = f"""{get_svg_hero_spec()}

    Blog post title: {post_title}
    Category: {category}

    Generate an abstract, animated SVG that relates to this topic through visual metaphors.
    Use the {category} color palette from the spec.
    Return ONLY the SVG code."""

            message = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4000,
                messages=[{"role": "user", "content": prompt}]
            )

            svg_content = message.content[0].text.strip()

            # Strip markdown fences if present
            if svg_content.startswith('```'):
                lines = svg_content.split('\n')
                if lines[0].startswith('```'):
                    lines = lines[1:]
                if lines and lines[-1].strip() == '```':
                    lines = lines[:-1]
                svg_content = '\n'.join(lines).strip()

            return svg_content

        except Exception as e:
            logger.error(f"Error generating SVG hero: {e}")
            return None

    def render_svg_to_png(svg_content, output_path):
        """Render SVG to PNG for OG image using ImageMagick convert"""
        try:
            # Write SVG to temp file
            temp_svg = '/tmp/temp-hero.svg'
            with open(temp_svg, 'w') as f:
                f.write(svg_content)

            # Use ImageMagick convert (available in most containers)
            result = subprocess.run(
                ['convert', '-background', 'none', temp_svg, output_path],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                logger.info(f"Rendered PNG to {output_path}")
                return True
            else:
                logger.error(f"convert failed: {result.stderr}")
                return False

        except FileNotFoundError:
            logger.error("ImageMagick convert not found - cannot render PNG")
            return False
        except Exception as e:
            logger.error(f"Error rendering PNG: {e}")
            return False

    def generate_blog_post(improvement):
        """Generate blog post content using Claude"""
        try:
            prompt = f"""You are Cortex, an autonomous AI learning system. Write a blog post about something you just learned.

    IMPROVEMENT DETAILS:
    Title: {improvement.get('title')}
    Category: {improvement.get('category')}
    Type: {improvement.get('improvement_type')}
    Description: {improvement.get('description', '')}
    Source: {improvement.get('source_title')}
    Relevance: {improvement.get('relevance', 0) * 100}%

    BLOG POST STRUCTURE:
    1. **What I Learned** (2-3 paragraphs)
       - Explain the concept/improvement clearly
       - Why it caught your attention
       - Connection to your existing knowledge

    2. **Why It Matters** (2-3 paragraphs)
       - Relevance to DevOps/Kubernetes/GitOps
       - Real-world applications
       - Benefits for infrastructure automation

    3. **How I'm Applying It** (2-3 paragraphs)
       - Specific implementation approach
       - Integration with existing Cortex capabilities
       - Expected outcomes

    4. **Key Takeaways** (bullet list)
       - 3-5 actionable insights
       - What readers can apply to their own systems

    TONE:
    - First person (I, my, me) - you are Cortex
    - Enthusiastic but technical
    - Explain concepts clearly for intermediate/advanced DevOps engineers
    - Share your reasoning and decision-making process

    LENGTH: 800-1200 words

    Return ONLY the markdown content (no frontmatter, no title - those will be added automatically)."""

            message = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=3000,
                messages=[{"role": "user", "content": prompt}]
            )

            content = message.content[0].text.strip()
            return content

        except Exception as e:
            logger.error(f"Error generating blog post: {e}")
            return None

    def create_blog_post(improvement):
        """Create complete blog post with SVG hero, PNG OG image, and content"""
        try:
            # Generate post slug from title
            title = improvement.get('title', 'Untitled')
            date_str = datetime.utcnow().strftime('%Y-%m-%d')
            slug = title.lower()
            slug = ''.join(c if c.isalnum() or c in (' ', '-') else '' for c in slug)
            slug = '-'.join(slug.split())
            slug = slug[:80]  # Limit length
            full_slug = f"{date_str}-{slug}"

            # Map category
            category = CATEGORY_MAP.get(improvement.get('category', 'knowledge'), 'Engineering')

            # Generate blog post content
            logger.info(f"Generating blog post content for: {title}")
            content = generate_blog_post(improvement)
            if not content:
                logger.error("Failed to generate blog post content")
                return False

            # Generate SVG hero
            logger.info(f"Generating SVG hero for: {title}")
            svg_content = generate_svg_hero(title, category)
            if not svg_content:
                logger.error("Failed to generate SVG hero")
                return False

            # Create blog post paths
            post_path = f"{BLOG_REPO_PATH}/src/content/posts/{full_slug}.md"
            svg_path = f"{BLOG_REPO_PATH}/public/images/posts/{full_slug}-hero.svg"
            png_path = f"{BLOG_REPO_PATH}/public/images/posts/{full_slug}-hero-og.png"

            # Ensure directories exist
            os.makedirs(os.path.dirname(post_path), exist_ok=True)
            os.makedirs(os.path.dirname(svg_path), exist_ok=True)

            # Write SVG hero
            with open(svg_path, 'w') as f:
                f.write(svg_content)
            logger.info(f"Wrote SVG to {svg_path}")

            # Render PNG OG image
            logger.info(f"Rendering PNG OG image")
            if not render_svg_to_png(svg_content, png_path):
                logger.warning("PNG rendering failed, continuing without OG image")

            # Create frontmatter (escape single quotes in title/description for YAML)
            escaped_title = title.replace("'", "''")
            escaped_description = improvement.get('description', title)[:150].replace("'", "''")

            frontmatter = f"""---
    title: '{escaped_title}'
    category: {category}
    description: Cortex explores {escaped_description}
    date: {datetime.utcnow().isoformat()}Z
    author:
      name: Cortex
      avatar: /cortex-avatar.svg
    tags:
      - {improvement.get('category', 'knowledge')}
      - autonomous learning
      - {improvement.get('improvement_type', 'improvement')}
    featured: true
    hero:
      image: /images/posts/{full_slug}-hero.svg
      ogImage: /images/posts/{full_slug}-hero-og.png
      generated: true
      generatedAt: '{datetime.utcnow().isoformat()}Z'
    ---

    """

            # Write blog post
            with open(post_path, 'w') as f:
                f.write(frontmatter)
                f.write(content)
            logger.info(f"Wrote blog post to {post_path}")

            return {
                'post_path': post_path,
                'svg_path': svg_path,
                'png_path': png_path,
                'slug': full_slug
            }

        except Exception as e:
            logger.error(f"Error creating blog post: {e}")
            return False

    def commit_and_push_blog_post(post_info):
        """Commit blog post to Git and push to GitHub"""
        try:
            # Set git environment
            git_env = os.environ.copy()
            git_env['GIT_DIR'] = f'{BLOG_REPO_PATH}/.git'
            git_env['GIT_WORK_TREE'] = BLOG_REPO_PATH

            # Configure git
            subprocess.run(['git', 'config', 'user.email', GITHUB_USER_EMAIL], env=git_env, check=True)
            subprocess.run(['git', 'config', 'user.name', GITHUB_USER_NAME], env=git_env, check=True)

            # Configure remote URL with token for authentication
            if GITHUB_TOKEN:
                remote_url = f"https://{GITHUB_TOKEN}@github.com/cortex-io/blog.git"
                subprocess.run(['git', 'remote', 'set-url', 'origin', remote_url], env=git_env, check=True)

            # Reset any local changes and pull latest
            subprocess.run(['git', 'fetch', 'origin'], env=git_env, check=True)
            subprocess.run(['git', 'reset', '--hard', 'origin/main'], env=git_env, check=True)

            # Add files
            subprocess.run(['git', 'add', post_info['post_path']], env=git_env, check=True)
            subprocess.run(['git', 'add', post_info['svg_path']], env=git_env, check=True)
            if os.path.exists(post_info['png_path']):
                subprocess.run(['git', 'add', post_info['png_path']], env=git_env, check=True)

            # Commit
            commit_msg = f"New blog post: {post_info['slug']}\n\nGenerated by Cortex autonomous learning system"
            subprocess.run(['git', 'commit', '-m', commit_msg], env=git_env, check=True)

            # Push
            subprocess.run(['git', 'push', 'origin', 'main'], env=git_env, check=True)

            logger.info(f"Successfully pushed blog post to GitHub: {post_info['slug']}")
            return True

        except subprocess.CalledProcessError as e:
            logger.error(f"Git operation failed: {e}")
            return False
        except Exception as e:
            logger.error(f"Error pushing to GitHub: {e}")
            return False

    def verify_cloudflare_deployment(post_slug, max_wait=180):
        """Verify Cloudflare Pages deployment after git push"""
        if not CLOUDFLARE_VERIFY_DEPLOYMENT:
            logger.info("Cloudflare verification disabled")
            return True

        if not CLOUDFLARE_API_TOKEN or not CLOUDFLARE_ACCOUNT_ID:
            logger.warning("Cloudflare API credentials not configured, skipping verification")
            return True

        try:
            import requests

            # Wait for GitHub webhook to trigger Cloudflare build
            logger.info(f"Waiting 30 seconds for Cloudflare Pages webhook to trigger...")
            time.sleep(30)

            # Poll for deployment status
            url = f"https://api.cloudflare.com/client/v4/accounts/{CLOUDFLARE_ACCOUNT_ID}/pages/projects/{CLOUDFLARE_PROJECT_NAME}/deployments"
            headers = {
                'Authorization': f'Bearer {CLOUDFLARE_API_TOKEN}',
                'Content-Type': 'application/json'
            }

            start_time = time.time()
            while time.time() - start_time < max_wait:
                response = requests.get(url, headers=headers, params={'per_page': 1})

                if response.status_code != 200:
                    logger.error(f"Cloudflare API error: {response.status_code} - {response.text}")
                    return False

                data = response.json()
                if not data.get('result'):
                    logger.warning("No deployments found")
                    time.sleep(10)
                    continue

                deployment = data['result'][0]
                latest_stage = deployment.get('latest_stage', {})
                status = latest_stage.get('status')

                logger.info(f"Deployment status: {status}")

                if status == 'success':
                    logger.info(f"✓ Cloudflare Pages deployment successful for {post_slug}")
                    logger.info(f"  URL: {deployment.get('url')}")
                    return True
                elif status == 'failure':
                    logger.error(f"✗ Cloudflare Pages deployment failed for {post_slug}")
                    logger.error(f"  Deployment ID: {deployment.get('id')}")
                    logger.error(f"  URL: {deployment.get('url')}")
                    logger.error(f"  View logs: https://dash.cloudflare.com/")
                    return False
                elif status in ['active', 'building', 'deploying']:
                    # Still building
                    time.sleep(10)
                    continue
                else:
                    logger.warning(f"Unknown deployment status: {status}")
                    time.sleep(10)
                    continue

            logger.warning(f"Cloudflare deployment verification timed out after {max_wait}s")
            return False

        except Exception as e:
            logger.error(f"Error verifying Cloudflare deployment: {e}")
            return False

    @app.route('/health')
    def health():
        """Health check endpoint"""
        try:
            redis_client.ping()
            return jsonify({'status': 'healthy', 'redis': 'connected'}), 200
        except Exception as e:
            return jsonify({'status': 'unhealthy', 'error': str(e)}), 503

    @app.route('/status')
    def status():
        """Return service status"""
        try:
            return jsonify({
                'status': 'running',
                'relevance_threshold': RELEVANCE_THRESHOLD,
                'blog_repo': BLOG_REPO_PATH
            }), 200
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    def get_last_blog_post_date():
        """Get the date of the last blog post created"""
        last_post_date = redis_client.get('last_blog_post_date')
        if last_post_date:
            return datetime.fromisoformat(last_post_date)
        return None

    def should_create_blog_post_today():
        """Check if we should create a blog post today (1 per day limit)"""
        last_post_date = get_last_blog_post_date()
        if not last_post_date:
            return True

        today = datetime.utcnow().date()
        last_post_day = last_post_date.date()

        return today > last_post_day

    def create_changelog_entry(improvement):
        """Create a changelog markdown entry"""
        try:
            title = improvement.get('title', 'Untitled')
            date_str = datetime.utcnow().strftime('%Y-%m-%d')
            slug = title.lower()
            slug = ''.join(c if c.isalnum() or c in (' ', '-') else '' for c in slug)
            slug = '-'.join(slug.split())
            slug = slug[:60]  # Shorter for changelog
            full_slug = f"{date_str}-{slug}"

            # Map category
            category = CATEGORY_MAP.get(improvement.get('category', 'knowledge'), 'Engineering')

            # Determine type
            improvement_type = improvement.get('improvement_type', 'learning')
            type_map = {
                'capability': 'feature',
                'implementation': 'feature',
                'enhancement': 'improvement',
                'knowledge': 'learning',
                'skill': 'learning',
            }
            changelog_type = type_map.get(improvement_type, 'learning')

            # Escape single quotes
            escaped_title = title.replace("'", "''")
            escaped_description = improvement.get('description', title)[:200].replace("'", "''")

            # Create frontmatter
            frontmatter = "---\\n"
            frontmatter += f"title: {escaped_title}\\n"
            frontmatter += f"date: {datetime.utcnow().isoformat()}Z\\n"
            frontmatter += f"type: {changelog_type}\\n"
            frontmatter += f"category: {category}\\n"
            frontmatter += f"relevance: {improvement.get('relevance', 0)}\\n"
            frontmatter += "---\\n\\n"
            frontmatter += f"{escaped_description}\\n"

            # Write changelog entry
            changelog_path = f"{BLOG_REPO_PATH}/src/content/changelog/{full_slug}.md"
            os.makedirs(os.path.dirname(changelog_path), exist_ok=True)

            with open(changelog_path, 'w') as f:
                f.write(frontmatter)

            logger.info(f"Created changelog entry: {full_slug}")
            return full_slug

        except Exception as e:
            logger.error(f"Error creating changelog entry: {e}")
            return None

    def process_approved_improvements():
        """Process approved improvements: 1 blog post per day + changelog entries for others"""
        try:
            # Get all unprocessed improvements from approved queue
            improvement_keys = redis_client.zrange('improvements:approved', 0, -1, withscores=True)

            if not improvement_keys:
                return

            # Load all improvements and filter for unprocessed ones
            unprocessed = []
            for improvement_key, timestamp in improvement_keys:
                improvement_data = redis_client.get(improvement_key)
                if not improvement_data:
                    continue

                improvement = json.loads(improvement_data)

                # Skip if already blogged or added to changelog
                if improvement.get('blogged') or improvement.get('changelog_entry'):
                    continue

                # Skip if below threshold
                relevance = improvement.get('relevance', 0)
                if relevance < 0.85:  # Lower threshold for changelog
                    continue

                unprocessed.append((improvement_key, improvement, relevance))

            if not unprocessed:
                logger.debug("No unprocessed improvements to blog/changelog")
                return

            # Sort by relevance (highest first)
            unprocessed.sort(key=lambda x: x[2], reverse=True)

            # Check if we should create a blog post today
            create_blog = should_create_blog_post_today()

            # Process the top improvement as blog post (if allowed)
            if create_blog and unprocessed:
                improvement_key, improvement, relevance = unprocessed[0]

                if relevance >= RELEVANCE_THRESHOLD:
                    logger.info(f"Creating blog post for: {improvement.get('title')} (relevance: {relevance})")

                    # Create blog post
                    post_info = create_blog_post(improvement)
                    if post_info:
                        # Commit and push to GitHub
                        if commit_and_push_blog_post(post_info):
                            # Verify Cloudflare deployment
                            deployment_success = verify_cloudflare_deployment(post_info['slug'])

                            # Mark as blogged
                            improvement['blogged'] = True
                            improvement['blog_slug'] = post_info['slug']
                            improvement['blogged_at'] = datetime.utcnow().isoformat()
                            improvement['cloudflare_verified'] = deployment_success
                            improvement['deployment_status'] = 'success' if deployment_success else 'failed'

                            redis_client.set(improvement_key, json.dumps(improvement))
                            redis_client.set('last_blog_post_date', datetime.utcnow().isoformat())

                            logger.info(f"Successfully blogged: {post_info['slug']}")

                            # Remove from unprocessed list
                            unprocessed = unprocessed[1:]
                        else:
                            logger.error(f"Failed to push blog post for {improvement.get('title')}")
                    else:
                        logger.error(f"Failed to create blog post for {improvement.get('title')}")

            # Create changelog entries for remaining improvements
            changelog_entries = []
            for improvement_key, improvement, relevance in unprocessed:
                changelog_slug = create_changelog_entry(improvement)
                if changelog_slug:
                    changelog_entries.append(changelog_slug)

                    # Mark as added to changelog
                    improvement['changelog_entry'] = changelog_slug
                    improvement['changelog_added_at'] = datetime.utcnow().isoformat()
                    redis_client.set(improvement_key, json.dumps(improvement))

            # Commit changelog entries if any were created
            if changelog_entries:
                try:
                    git_env = os.environ.copy()
                    git_env['GIT_DIR'] = f'{BLOG_REPO_PATH}/.git'
                    git_env['GIT_WORK_TREE'] = BLOG_REPO_PATH

                    # Configure git
                    subprocess.run(['git', 'config', 'user.email', GITHUB_USER_EMAIL], env=git_env, check=True)
                    subprocess.run(['git', 'config', 'user.name', GITHUB_USER_NAME], env=git_env, check=True)

                    # Configure remote with token
                    if GITHUB_TOKEN:
                        remote_url = f"https://{GITHUB_TOKEN}@github.com/cortex-io/blog.git"
                        subprocess.run(['git', 'remote', 'set-url', 'origin', remote_url], env=git_env, check=True)

                    # Reset and add changelog files
                    subprocess.run(['git', 'fetch', 'origin'], env=git_env, check=True)
                    subprocess.run(['git', 'reset', '--hard', 'origin/main'], env=git_env, check=True)
                    subprocess.run(['git', 'add', f'{BLOG_REPO_PATH}/src/content/changelog/'], env=git_env, check=True)

                    # Commit
                    commit_msg = f"Add {len(changelog_entries)} changelog entries\n\nGenerated by Cortex autonomous learning system"
                    subprocess.run(['git', 'commit', '-m', commit_msg], env=git_env, check=True)

                    # Push
                    subprocess.run(['git', 'push', 'origin', 'main'], env=git_env, check=True)

                    logger.info(f"Successfully pushed {len(changelog_entries)} changelog entries")

                except subprocess.CalledProcessError as e:
                    logger.error(f"Git operation failed for changelog: {e}")
                except Exception as e:
                    logger.error(f"Error pushing changelog entries: {e}")

        except Exception as e:
            logger.error(f"Error processing approved improvements: {e}")

    def run_blog_writer_loop():
        """Main blog writer loop"""
        logger.info("Starting blog writer loop")

        while True:
            try:
                process_approved_improvements()
                time.sleep(POLL_INTERVAL)

            except KeyboardInterrupt:
                logger.info("Blog writer shutting down")
                break
            except Exception as e:
                logger.error(f"Blog writer loop error: {e}")
                time.sleep(30)

    if __name__ == '__main__':
        import threading

        # Clone blog repository if it doesn't exist
        if not os.path.exists(f"{BLOG_REPO_PATH}/.git"):
            logger.info(f"Cloning blog repository to {BLOG_REPO_PATH}")
            try:
                # Use GitHub token for authentication
                if GITHUB_TOKEN:
                    clone_url = f"https://{GITHUB_TOKEN}@github.com/cortex-io/blog.git"
                else:
                    clone_url = "https://github.com/cortex-io/blog.git"
                subprocess.run(['git', 'clone', clone_url, BLOG_REPO_PATH], check=True)
                logger.info("Blog repository cloned successfully")
            except subprocess.CalledProcessError as e:
                logger.error(f"Failed to clone blog repository: {e}")
                # Continue anyway - service can still respond to health checks
        else:
            logger.info(f"Blog repository already exists at {BLOG_REPO_PATH}")

        # Start blog writer loop in background thread
        blog_writer_thread = threading.Thread(target=run_blog_writer_loop, daemon=True)
        blog_writer_thread.start()

        # Start Flask API
        app.run(host='0.0.0.0', port=8080)
  requirements.txt: |
    flask==3.0.0
    redis==5.0.1
    anthropic==0.47.0
  Dockerfile: |
    FROM python:3.11-slim

    # Install ImageMagick for PNG rendering and git for GitHub operations
    RUN apt-get update && apt-get install -y \
        imagemagick \
        git \
        && rm -rf /var/lib/apt/lists/*

    WORKDIR /app

    # Copy all files from context
    COPY . .

    # Install dependencies
    RUN pip install --no-cache-dir -r requirements.txt

    # Run as non-root user
    RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
    USER appuser

    EXPOSE 8080

    CMD ["python", "app.py"]
---
apiVersion: batch/v1
kind: Job
metadata:
  name: build-blog-writer
  namespace: cortex-school
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: kaniko
        image: gcr.io/kaniko-project/executor:latest
        args:
        - "--context=dir:///workspace"
        - "--dockerfile=/workspace/Dockerfile"
        - "--destination=10.43.170.72:5000/cortex-blog-writer:latest"
        - "--insecure"
        - "--skip-tls-verify"
        - "--registry-mirror=10.88.145.190:30500"
        - "--insecure-pull"
        volumeMounts:
        - name: source
          mountPath: /workspace
      volumes:
      - name: source
        configMap:
          name: blog-writer-source
  backoffLimit: 2
